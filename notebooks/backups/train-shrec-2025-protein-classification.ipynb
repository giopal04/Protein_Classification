{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PointNet to Classify Proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8ugd_8:R:3U_model1.vtk', '8h0v_18:R:c_model1.vtk', '3j3q_1:DX:4F_model1.vtk', '4u4u_23:XC:d1_model1.vtk', '6rny_4:H:H_model1.vtk']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9285 entries, 0 to 9284\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   protein_id        9285 non-null   object\n",
      " 1   class_id          9285 non-null   int64 \n",
      " 2   number_of_points  9285 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 290.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>number_of_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ugd_8:R:3U_model1</td>\n",
       "      <td>96</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8h0v_18:R:c_model1</td>\n",
       "      <td>86</td>\n",
       "      <td>10078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3j3q_1:DX:4F_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>4150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4u4u_23:XC:d1_model1</td>\n",
       "      <td>83</td>\n",
       "      <td>8242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6rny_4:H:H_model1</td>\n",
       "      <td>34</td>\n",
       "      <td>9204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280</th>\n",
       "      <td>3j3y_1:HL:6R_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>4u4y_15:O:C3_model1</td>\n",
       "      <td>91</td>\n",
       "      <td>12976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9282</th>\n",
       "      <td>7w31_26:AA:c_model1</td>\n",
       "      <td>18</td>\n",
       "      <td>16454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9283</th>\n",
       "      <td>3j4k_1:E:E_model1</td>\n",
       "      <td>90</td>\n",
       "      <td>23188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>3j3y_1:UIA:fE_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>17888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                protein_id  class_id  number_of_points\n",
       "0       8ugd_8:R:3U_model1        96              1420\n",
       "1       8h0v_18:R:c_model1        86             10078\n",
       "2      3j3q_1:DX:4F_model1         8              4150\n",
       "3     4u4u_23:XC:d1_model1        83              8242\n",
       "4        6rny_4:H:H_model1        34              9204\n",
       "...                    ...       ...               ...\n",
       "9280   3j3y_1:HL:6R_model1         8              4030\n",
       "9281   4u4y_15:O:C3_model1        91             12976\n",
       "9282   7w31_26:AA:c_model1        18             16454\n",
       "9283     3j4k_1:E:E_model1        90             23188\n",
       "9284  3j3y_1:UIA:fE_model1         8             17888\n",
       "\n",
       "[9285 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the data\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from datasetStudy import *\n",
    "\n",
    "# Multiple functions here depend on the variable\n",
    "base_path = Path('/mnt/raid1')\n",
    "#base_path = Path('/mnt')\n",
    "root = base_path / 'dataset/shrec-2025-protein-classification/v2-20250331' \n",
    "\n",
    "train_data = os.listdir(root / 'train')\n",
    "train_data_cls = pd.read_csv('./datasets/train_set-all.csv', sep=',', index_col=0)\n",
    "\n",
    "print(train_data[:5])\n",
    "print()\n",
    "print(train_data_cls.info())\n",
    "train_data_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>number_of_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3j3q_1:DX:4F_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>4150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3j3y_1:FOA:56_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>4330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3j3q_1:LX:aS_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>3764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3j3q_1:RAA:eh_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3j3q_1:NBA:bQ_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>4178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9264</th>\n",
       "      <td>3j3q_1:RA:eg_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>3754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9267</th>\n",
       "      <td>3j3y_1:GV:6_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>4004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>3j3q_1:IAA:7g_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>3696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>3j3y_1:CT:33_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>4174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9280</th>\n",
       "      <td>3j3y_1:HL:6R_model1</td>\n",
       "      <td>8</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                protein_id  class_id  number_of_points\n",
       "2      3j3q_1:DX:4F_model1         8              4150\n",
       "11    3j3y_1:FOA:56_model1         8              4330\n",
       "19     3j3q_1:LX:aS_model1         8              3764\n",
       "22    3j3q_1:RAA:eh_model1         8              3884\n",
       "25    3j3q_1:NBA:bQ_model1         8              4178\n",
       "...                    ...       ...               ...\n",
       "9264   3j3q_1:RA:eg_model1         8              3754\n",
       "9267    3j3y_1:GV:6_model1         8              4004\n",
       "9272  3j3q_1:IAA:7g_model1         8              3696\n",
       "9273   3j3y_1:CT:33_model1         8              4174\n",
       "9280   3j3y_1:HL:6R_model1         8              4030\n",
       "\n",
       "[761 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_disconnected_mesh(train_data_cls, 96, False)\n",
    "\n",
    "disconnected_dict = {}\n",
    "for idx in range(97):\n",
    "    disconnected_dict[idx] = possible_disconnected_mesh(train_data_cls, idx)\n",
    "\n",
    "#print(disconnected_dict)\n",
    "\n",
    "_, damaged = possible_disconnected_mesh(train_data_cls, 8, True)\n",
    "\n",
    "damaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes which have between 0 and 5 element: 16/97\n"
     ]
    }
   ],
   "source": [
    "dist = cls_distribution(train_data_cls)\n",
    "inspect_distribution(dist, l_lim=0, u_lim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls 0: 101\t97\t97\t97\t0\t0\t\n",
      "cls 1: 3\t3\t0\t0\t0\t0\t\n",
      "cls 2: 17\t17\t17\t17\t17\t0\t\n",
      "cls 3: 21\t18\t18\t18\t18\t0\t\n",
      "cls 4: 15\t15\t15\t15\t15\t0\t\n",
      "cls 5: 127\t127\t127\t0\t0\t127\t\n",
      "cls 6: 25\t21\t21\t21\t21\t0\t\n",
      "cls 7: 75\t75\t75\t75\t0\t0\t\n",
      "cls 8: 2054\t1293\t1293\t0\t0\t1293\t\n",
      "cls 9: 66\t66\t66\t66\t0\t0\t\n",
      "cls 10: 14\t14\t14\t14\t14\t0\t\n",
      "cls 11: 43\t43\t43\t43\t43\t0\t\n",
      "cls 12: 10\t10\t10\t10\t10\t0\t\n",
      "cls 13: 22\t22\t22\t22\t22\t0\t\n",
      "cls 14: 497\t497\t497\t0\t0\t497\t\n",
      "cls 15: 89\t89\t89\t89\t0\t0\t\n",
      "cls 16: 154\t154\t154\t0\t0\t154\t\n",
      "cls 17: 116\t115\t115\t0\t0\t115\t\n",
      "cls 18: 76\t63\t63\t63\t0\t0\t\n",
      "cls 19: 45\t45\t45\t45\t45\t0\t\n",
      "cls 20: 7\t5\t0\t0\t0\t0\t\n",
      "cls 21: 74\t74\t74\t74\t0\t0\t\n",
      "cls 22: 58\t58\t58\t58\t0\t0\t\n",
      "cls 23: 10\t10\t10\t10\t10\t0\t\n",
      "cls 24: 10\t10\t10\t10\t10\t0\t\n",
      "cls 25: 143\t143\t143\t0\t0\t143\t\n",
      "cls 26: 2\t2\t0\t0\t0\t0\t\n",
      "cls 27: 3\t3\t0\t0\t0\t0\t\n",
      "cls 28: 18\t13\t13\t13\t13\t0\t\n",
      "cls 29: 14\t14\t14\t14\t14\t0\t\n",
      "cls 30: 3\t3\t0\t0\t0\t0\t\n",
      "cls 31: 33\t33\t33\t33\t33\t0\t\n",
      "cls 32: 93\t93\t93\t93\t0\t0\t\n",
      "cls 33: 126\t125\t125\t0\t0\t125\t\n",
      "cls 34: 73\t73\t73\t73\t0\t0\t\n",
      "cls 35: 23\t23\t23\t23\t23\t0\t\n",
      "cls 36: 8\t8\t0\t0\t0\t0\t\n",
      "cls 37: 119\t116\t116\t0\t0\t116\t\n",
      "cls 38: 34\t34\t34\t34\t34\t0\t\n",
      "cls 39: 19\t19\t19\t19\t19\t0\t\n",
      "cls 40: 97\t97\t97\t97\t0\t0\t\n",
      "cls 41: 111\t107\t107\t0\t0\t107\t\n",
      "cls 42: 2\t2\t0\t0\t0\t0\t\n",
      "cls 43: 70\t70\t70\t70\t0\t0\t\n",
      "cls 44: 2\t2\t0\t0\t0\t0\t\n",
      "cls 45: 109\t109\t109\t0\t0\t109\t\n",
      "cls 46: 44\t44\t44\t44\t44\t0\t\n",
      "cls 47: 37\t37\t37\t37\t37\t0\t\n",
      "cls 48: 27\t10\t10\t10\t10\t0\t\n",
      "cls 49: 49\t49\t49\t49\t49\t0\t\n",
      "cls 50: 2\t2\t0\t0\t0\t0\t\n",
      "cls 51: 71\t71\t71\t71\t0\t0\t\n",
      "cls 52: 76\t76\t76\t76\t0\t0\t\n",
      "cls 53: 53\t53\t53\t53\t0\t0\t\n",
      "cls 54: 128\t128\t128\t0\t0\t128\t\n",
      "cls 55: 26\t26\t26\t26\t26\t0\t\n",
      "cls 56: 657\t655\t655\t0\t0\t655\t\n",
      "cls 57: 9\t9\t0\t0\t0\t0\t\n",
      "cls 58: 2\t2\t0\t0\t0\t0\t\n",
      "cls 59: 54\t54\t54\t54\t0\t0\t\n",
      "cls 60: 73\t71\t71\t71\t0\t0\t\n",
      "cls 61: 240\t240\t240\t0\t0\t240\t\n",
      "cls 62: 135\t134\t134\t0\t0\t134\t\n",
      "cls 63: 2\t2\t0\t0\t0\t0\t\n",
      "cls 64: 57\t57\t57\t57\t0\t0\t\n",
      "cls 65: 10\t10\t10\t10\t10\t0\t\n",
      "cls 66: 54\t54\t54\t54\t0\t0\t\n",
      "cls 67: 17\t17\t17\t17\t17\t0\t\n",
      "cls 68: 5\t5\t0\t0\t0\t0\t\n",
      "cls 69: 80\t78\t78\t78\t0\t0\t\n",
      "cls 70: 223\t223\t223\t0\t0\t223\t\n",
      "cls 71: 102\t102\t102\t0\t0\t102\t\n",
      "cls 72: 2\t2\t0\t0\t0\t0\t\n",
      "cls 73: 6\t1\t0\t0\t0\t0\t\n",
      "cls 74: 150\t149\t149\t0\t0\t149\t\n",
      "cls 75: 69\t69\t69\t69\t0\t0\t\n",
      "cls 76: 10\t10\t10\t10\t10\t0\t\n",
      "cls 77: 2\t2\t0\t0\t0\t0\t\n",
      "cls 78: 5\t2\t0\t0\t0\t0\t\n",
      "cls 79: 78\t78\t78\t78\t0\t0\t\n",
      "cls 80: 57\t57\t57\t57\t0\t0\t\n",
      "cls 81: 58\t58\t58\t58\t0\t0\t\n",
      "cls 82: 2\t2\t0\t0\t0\t0\t\n",
      "cls 83: 115\t115\t115\t0\t0\t115\t\n",
      "cls 84: 18\t18\t18\t18\t18\t0\t\n",
      "cls 85: 58\t51\t51\t51\t0\t0\t\n",
      "cls 86: 203\t201\t201\t0\t0\t201\t\n",
      "cls 87: 103\t103\t103\t0\t0\t103\t\n",
      "cls 88: 97\t97\t97\t97\t0\t0\t\n",
      "cls 89: 3\t3\t0\t0\t0\t0\t\n",
      "cls 90: 788\t788\t788\t0\t0\t788\t\n",
      "cls 91: 118\t118\t118\t0\t0\t118\t\n",
      "cls 92: 129\t126\t126\t0\t0\t126\t\n",
      "cls 93: 61\t61\t61\t61\t0\t0\t\n",
      "cls 94: 52\t52\t52\t52\t0\t0\t\n",
      "cls 95: 2\t2\t0\t0\t0\t0\t\n",
      "cls 96: 35\t17\t17\t17\t17\t0\t\n",
      "len(train_data_cls) = 9285\n",
      "len(train_data_f1) = 8421\n",
      "len(train_data_f2) = 8359\n",
      "len(train_data_f3) = 2491\n",
      "len(train_data_f4) = 599\n",
      "len(train_data_f5) = 5868\n"
     ]
    }
   ],
   "source": [
    "dist_all = cls_distribution(train_data_cls)\n",
    "\n",
    "train_data_f1 = number_of_point_filter(train_data_cls, 5000)\n",
    "dist_f1 = cls_distribution(train_data_f1)\n",
    "\n",
    "train_data_f2 = number_of_class_filter(train_data_f1, 10)\n",
    "dist_f2 = cls_distribution(train_data_f2)\n",
    "\n",
    "train_data_f3 = number_of_class_filter(train_data_f1, 10, 100)\n",
    "dist_f3 = cls_distribution(train_data_f3)\n",
    "\n",
    "train_data_f4 = number_of_class_filter(train_data_f1, 10, 50)\n",
    "dist_f4 = cls_distribution(train_data_f4)\n",
    "\n",
    "train_data_f5 = number_of_class_filter(train_data_f1, 100)\n",
    "dist_f5 = cls_distribution(train_data_f5)\n",
    "\n",
    "distributions = [dist_all, dist_f1, dist_f2, dist_f3, dist_f4, dist_f5]\n",
    "for idx in range(len(dist_all)):\n",
    "    output = f'cls {idx}: '\n",
    "    for dist in distributions:\n",
    "        output += f'{print_dist(dist, idx)}\\t'\n",
    "    print(output)\n",
    "\n",
    "print(f'{len(train_data_cls) = }')\n",
    "print(f'{len(train_data_f1) = }')\n",
    "print(f'{len(train_data_f2) = }')\n",
    "print(f'{len(train_data_f3) = }')\n",
    "print(f'{len(train_data_f4) = }')\n",
    "print(f'{len(train_data_f5) = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata_set_3.to_csv('datasets/train_set-filtered-2_cls-1000_images.csv')\\ndata_set_4.to_csv('datasets/train_set-filtered-10_cls-1000_images.csv')\\ndata_set_5.to_csv('datasets/train_set-filtered-20_cls-1000_images.csv')\\ndata_set_6.to_csv('datasets/train_set-filtered-20_cls-2000_images.csv')\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_selected = [8, 90, 56, 14, 61, 70, 86, 5, 16, 25, 54, 62, 74, 83, 91, 92, 17, 45, 87, 41]\n",
    "\n",
    "data_set_3 = create_dataset(train_data_f1, cls_selected[:2], 500)\n",
    "data_set_4 = create_dataset(train_data_f1, cls_selected[:10], 100)\n",
    "data_set_5 = create_dataset(train_data_f1, cls_selected[:20], 50)\n",
    "data_set_6 = create_dataset(train_data_f1, cls_selected[:20], 100)\n",
    "\n",
    "'''\n",
    "data_set_3.to_csv('./datasets/train_set-filtered-2_cls-1000_images.csv')\n",
    "data_set_4.to_csv('./datasets/train_set-filtered-10_cls-1000_images.csv')\n",
    "data_set_5.to_csv('./datasets/train_set-filtered-20_cls-1000_images.csv')\n",
    "data_set_6.to_csv('./datasets/train_set-filtered-20_cls-2000_images.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find duplicate protein_id(s) in the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9285"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_cls['protein_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9244"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_cls['protein_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 duplicate protein_id(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>number_of_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>6vz4_3:G:G_model10</td>\n",
       "      <td>40</td>\n",
       "      <td>10186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>1klv_1:A:A_model17</td>\n",
       "      <td>85</td>\n",
       "      <td>8588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>7pj1_1:A:A_model20</td>\n",
       "      <td>14</td>\n",
       "      <td>13872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>1k0t_1:A:A_model26</td>\n",
       "      <td>41</td>\n",
       "      <td>7572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>1k0t_1:A:A_model30</td>\n",
       "      <td>41</td>\n",
       "      <td>7244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>1myf_1:A:A_model11</td>\n",
       "      <td>19</td>\n",
       "      <td>10746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>1k0t_1:A:A_model12</td>\n",
       "      <td>41</td>\n",
       "      <td>7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>1myf_1:A:A_model12</td>\n",
       "      <td>19</td>\n",
       "      <td>10390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>1k0t_1:A:A_model13</td>\n",
       "      <td>41</td>\n",
       "      <td>7318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>1klv_1:A:A_model12</td>\n",
       "      <td>85</td>\n",
       "      <td>8744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5341</th>\n",
       "      <td>1klv_1:A:A_model15</td>\n",
       "      <td>85</td>\n",
       "      <td>8716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>2rvq_2:B:D_model10</td>\n",
       "      <td>56</td>\n",
       "      <td>14280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>1k0t_1:A:A_model19</td>\n",
       "      <td>41</td>\n",
       "      <td>7386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484</th>\n",
       "      <td>1k0t_1:A:A_model24</td>\n",
       "      <td>41</td>\n",
       "      <td>7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>1k0t_1:A:A_model27</td>\n",
       "      <td>41</td>\n",
       "      <td>7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>7pj1_1:A:A_model18</td>\n",
       "      <td>14</td>\n",
       "      <td>14308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>1klv_1:A:A_model11</td>\n",
       "      <td>85</td>\n",
       "      <td>8870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>1k0t_1:A:A_model10</td>\n",
       "      <td>41</td>\n",
       "      <td>7082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101</th>\n",
       "      <td>7pj1_1:A:A_model12</td>\n",
       "      <td>14</td>\n",
       "      <td>13968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>1myf_1:A:A_model10</td>\n",
       "      <td>19</td>\n",
       "      <td>10928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>1klv_1:A:A_model19</td>\n",
       "      <td>85</td>\n",
       "      <td>8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>7pj1_1:A:A_model13</td>\n",
       "      <td>14</td>\n",
       "      <td>13970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>1klv_1:A:A_model13</td>\n",
       "      <td>85</td>\n",
       "      <td>8964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6891</th>\n",
       "      <td>7pj1_1:A:A_model17</td>\n",
       "      <td>14</td>\n",
       "      <td>13492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>1k0t_1:A:A_model18</td>\n",
       "      <td>41</td>\n",
       "      <td>7528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186</th>\n",
       "      <td>1klv_1:A:A_model20</td>\n",
       "      <td>85</td>\n",
       "      <td>8908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1k0t_1:A:A_model28</td>\n",
       "      <td>41</td>\n",
       "      <td>7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304</th>\n",
       "      <td>1k0t_1:A:A_model17</td>\n",
       "      <td>41</td>\n",
       "      <td>7404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7381</th>\n",
       "      <td>1klv_1:A:A_model18</td>\n",
       "      <td>85</td>\n",
       "      <td>8954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>7pj1_1:A:A_model14</td>\n",
       "      <td>14</td>\n",
       "      <td>14170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7555</th>\n",
       "      <td>1k0t_1:A:A_model22</td>\n",
       "      <td>41</td>\n",
       "      <td>7262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>1k0t_1:A:A_model21</td>\n",
       "      <td>41</td>\n",
       "      <td>7356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>7pj1_1:A:A_model11</td>\n",
       "      <td>14</td>\n",
       "      <td>13824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8022</th>\n",
       "      <td>6vz4_4:D:D_model10</td>\n",
       "      <td>56</td>\n",
       "      <td>9048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8235</th>\n",
       "      <td>1k0t_1:A:A_model25</td>\n",
       "      <td>41</td>\n",
       "      <td>7154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>1k0t_1:A:A_model14</td>\n",
       "      <td>41</td>\n",
       "      <td>7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>7pj1_1:A:A_model10</td>\n",
       "      <td>14</td>\n",
       "      <td>14700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8604</th>\n",
       "      <td>6vz4_4:H:H_model10</td>\n",
       "      <td>56</td>\n",
       "      <td>9038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>1klv_1:A:A_model16</td>\n",
       "      <td>85</td>\n",
       "      <td>8642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>1k0t_1:A:A_model15</td>\n",
       "      <td>41</td>\n",
       "      <td>7552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>6vz4_3:C:C_model10</td>\n",
       "      <td>40</td>\n",
       "      <td>10232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              protein_id  class_id  number_of_points\n",
       "1472  6vz4_3:G:G_model10        40             10186\n",
       "2552  1klv_1:A:A_model17        85              8588\n",
       "3120  7pj1_1:A:A_model20        14             13872\n",
       "3559  1k0t_1:A:A_model26        41              7572\n",
       "3670  1k0t_1:A:A_model30        41              7244\n",
       "4710  1myf_1:A:A_model11        19             10746\n",
       "4756  1k0t_1:A:A_model12        41              7400\n",
       "5008  1myf_1:A:A_model12        19             10390\n",
       "5034  1k0t_1:A:A_model13        41              7318\n",
       "5121  1klv_1:A:A_model12        85              8744\n",
       "5341  1klv_1:A:A_model15        85              8716\n",
       "5398  2rvq_2:B:D_model10        56             14280\n",
       "5471  1k0t_1:A:A_model19        41              7386\n",
       "5484  1k0t_1:A:A_model24        41              7192\n",
       "5546  1k0t_1:A:A_model27        41              7500\n",
       "5621  7pj1_1:A:A_model18        14             14308\n",
       "5751  1klv_1:A:A_model11        85              8870\n",
       "6055  1k0t_1:A:A_model10        41              7082\n",
       "6101  7pj1_1:A:A_model12        14             13968\n",
       "6126  1myf_1:A:A_model10        19             10928\n",
       "6144  1klv_1:A:A_model19        85              8714\n",
       "6156  7pj1_1:A:A_model13        14             13970\n",
       "6658  1klv_1:A:A_model13        85              8964\n",
       "6891  7pj1_1:A:A_model17        14             13492\n",
       "7098  1k0t_1:A:A_model18        41              7528\n",
       "7186  1klv_1:A:A_model20        85              8908\n",
       "7192  1k0t_1:A:A_model28        41              7204\n",
       "7304  1k0t_1:A:A_model17        41              7404\n",
       "7381  1klv_1:A:A_model18        85              8954\n",
       "7533  7pj1_1:A:A_model14        14             14170\n",
       "7555  1k0t_1:A:A_model22        41              7262\n",
       "7608  1k0t_1:A:A_model21        41              7356\n",
       "7834  7pj1_1:A:A_model11        14             13824\n",
       "8022  6vz4_4:D:D_model10        56              9048\n",
       "8235  1k0t_1:A:A_model25        41              7154\n",
       "8513  1k0t_1:A:A_model14        41              7184\n",
       "8530  7pj1_1:A:A_model10        14             14700\n",
       "8604  6vz4_4:H:H_model10        56              9038\n",
       "8998  1klv_1:A:A_model16        85              8642\n",
       "9009  1k0t_1:A:A_model15        41              7552\n",
       "9250  6vz4_3:C:C_model10        40             10232"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_df = train_data_cls[train_data_cls.duplicated(['protein_id'], keep='first')]\n",
    "print(f'Found {len(duplicates_df)} duplicate protein_id(s)')\n",
    "duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6vz4_3:G:G_model10',\n",
       " '1klv_1:A:A_model17',\n",
       " '7pj1_1:A:A_model20',\n",
       " '1k0t_1:A:A_model26',\n",
       " '1k0t_1:A:A_model30',\n",
       " '1myf_1:A:A_model11',\n",
       " '1k0t_1:A:A_model12',\n",
       " '1myf_1:A:A_model12',\n",
       " '1k0t_1:A:A_model13',\n",
       " '1klv_1:A:A_model12',\n",
       " '1klv_1:A:A_model15',\n",
       " '2rvq_2:B:D_model10',\n",
       " '1k0t_1:A:A_model19',\n",
       " '1k0t_1:A:A_model24',\n",
       " '1k0t_1:A:A_model27',\n",
       " '7pj1_1:A:A_model18',\n",
       " '1klv_1:A:A_model11',\n",
       " '1k0t_1:A:A_model10',\n",
       " '7pj1_1:A:A_model12',\n",
       " '1myf_1:A:A_model10',\n",
       " '1klv_1:A:A_model19',\n",
       " '7pj1_1:A:A_model13',\n",
       " '1klv_1:A:A_model13',\n",
       " '7pj1_1:A:A_model17',\n",
       " '1k0t_1:A:A_model18',\n",
       " '1klv_1:A:A_model20',\n",
       " '1k0t_1:A:A_model28',\n",
       " '1k0t_1:A:A_model17',\n",
       " '1klv_1:A:A_model18',\n",
       " '7pj1_1:A:A_model14',\n",
       " '1k0t_1:A:A_model22',\n",
       " '1k0t_1:A:A_model21',\n",
       " '7pj1_1:A:A_model11',\n",
       " '6vz4_4:D:D_model10',\n",
       " '1k0t_1:A:A_model25',\n",
       " '1k0t_1:A:A_model14',\n",
       " '7pj1_1:A:A_model10',\n",
       " '6vz4_4:H:H_model10',\n",
       " '1klv_1:A:A_model16',\n",
       " '1k0t_1:A:A_model15',\n",
       " '6vz4_3:C:C_model10']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_lst = list(duplicates_df['protein_id'].values)\n",
    "dupe_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "1k0t_1:A:A_model18\n",
      "1k0t_1:A:A_model30\n",
      "1k0t_1:A:A_model13\n",
      "1k0t_1:A:A_model27\n",
      "6vz4_3:C:C_model10\n",
      "6vz4_3:G:G_model10\n",
      "1klv_1:A:A_model11\n",
      "1klv_1:A:A_model17\n",
      "1k0t_1:A:A_model21\n",
      "1k0t_1:A:A_model26\n",
      "7pj1_1:A:A_model20\n",
      "1myf_1:A:A_model11\n",
      "1k0t_1:A:A_model12\n",
      "1myf_1:A:A_model10\n",
      "1klv_1:A:A_model15\n",
      "1klv_1:A:A_model16\n",
      "1k0t_1:A:A_model22\n",
      "1k0t_1:A:A_model28\n",
      "7pj1_1:A:A_model12\n",
      "1klv_1:A:A_model12\n",
      "1k0t_1:A:A_model24\n",
      "1myf_1:A:A_model12\n",
      "1k0t_1:A:A_model19\n",
      "1k0t_1:A:A_model14\n",
      "1klv_1:A:A_model20\n",
      "7pj1_1:A:A_model10\n",
      "7pj1_1:A:A_model11\n",
      "7pj1_1:A:A_model18\n",
      "7pj1_1:A:A_model14\n",
      "7pj1_1:A:A_model13\n",
      "1klv_1:A:A_model19\n",
      "7pj1_1:A:A_model17\n",
      "1klv_1:A:A_model13\n",
      "2rvq_2:B:D_model10\n",
      "1k0t_1:A:A_model17\n",
      "6vz4_4:H:H_model10\n",
      "1k0t_1:A:A_model10\n",
      "1k0t_1:A:A_model25\n",
      "1klv_1:A:A_model18\n",
      "1k0t_1:A:A_model15\n",
      "6vz4_4:D:D_model10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''''\n",
    "check_for_duplicate = {}\n",
    "\n",
    "for prot in train_data_cls['protein_id']:\n",
    "    df = train_data_cls[train_data_cls['protein_id'] == prot]\n",
    "    check_for_duplicate[prot] = list(df['class_id'])\n",
    "\n",
    "count = 0\n",
    "duplicates = []\n",
    "for prot in check_for_duplicate:\n",
    "    if len(check_for_duplicate[prot]) > 1:\n",
    "        duplicates.append(prot)\n",
    "        count += 1\n",
    "\n",
    "print(count)\n",
    "for el in duplicates:\n",
    "    print(el)\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1k0t_1:A:A_model18: [41, 41]\n",
      "1k0t_1:A:A_model30: [41, 41]\n",
      "1k0t_1:A:A_model13: [41, 41]\n",
      "1k0t_1:A:A_model27: [41, 41]\n",
      "6vz4_3:C:C_model10: [40, 40]\n",
      "6vz4_3:G:G_model10: [40, 40]\n",
      "1klv_1:A:A_model11: [85, 85]\n",
      "1klv_1:A:A_model17: [85, 85]\n",
      "1k0t_1:A:A_model21: [41, 41]\n",
      "1k0t_1:A:A_model26: [41, 41]\n",
      "7pj1_1:A:A_model20: [14, 14]\n",
      "1myf_1:A:A_model11: [19, 19]\n",
      "1k0t_1:A:A_model12: [41, 41]\n",
      "1myf_1:A:A_model10: [19, 19]\n",
      "1klv_1:A:A_model15: [85, 85]\n",
      "1klv_1:A:A_model16: [85, 85]\n",
      "1k0t_1:A:A_model22: [41, 41]\n",
      "1k0t_1:A:A_model28: [41, 41]\n",
      "7pj1_1:A:A_model12: [14, 14]\n",
      "1klv_1:A:A_model12: [85, 85]\n",
      "1k0t_1:A:A_model24: [41, 41]\n",
      "1myf_1:A:A_model12: [19, 19]\n",
      "1k0t_1:A:A_model19: [41, 41]\n",
      "1k0t_1:A:A_model14: [41, 41]\n",
      "1klv_1:A:A_model20: [85, 85]\n",
      "7pj1_1:A:A_model10: [14, 14]\n",
      "7pj1_1:A:A_model11: [14, 14]\n",
      "7pj1_1:A:A_model18: [14, 14]\n",
      "7pj1_1:A:A_model14: [14, 14]\n",
      "7pj1_1:A:A_model13: [14, 14]\n",
      "1klv_1:A:A_model19: [85, 85]\n",
      "7pj1_1:A:A_model17: [14, 14]\n",
      "1klv_1:A:A_model13: [85, 85]\n",
      "2rvq_2:B:D_model10: [56, 56]\n",
      "1k0t_1:A:A_model17: [41, 41]\n",
      "6vz4_4:H:H_model10: [56, 56]\n",
      "1k0t_1:A:A_model10: [41, 41]\n",
      "1k0t_1:A:A_model25: [41, 41]\n",
      "1klv_1:A:A_model18: [85, 85]\n",
      "1k0t_1:A:A_model15: [41, 41]\n",
      "6vz4_4:D:D_model10: [56, 56]\n"
     ]
    }
   ],
   "source": [
    "for duplicate in duplicates:\n",
    "    print(f'{duplicate}: {check_for_duplicate[duplicate]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab a test dataframe for the first round of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 88])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('datasets/train_set-2_cls-194_images.csv')\n",
    "test['class_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>protein_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>number_of_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6vz4_3:G:G_model5</td>\n",
       "      <td>40</td>\n",
       "      <td>10134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8g6g_3:G:G_model1</td>\n",
       "      <td>40</td>\n",
       "      <td>10180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6vz4_3:C:C_model9</td>\n",
       "      <td>40</td>\n",
       "      <td>10190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8tof_10:L:c_model1</td>\n",
       "      <td>40</td>\n",
       "      <td>9678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8du4_3:G:G_model1</td>\n",
       "      <td>40</td>\n",
       "      <td>10420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>8f9j_1:A:A_model1</td>\n",
       "      <td>88</td>\n",
       "      <td>10608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>1j3f_1:A:A_model1</td>\n",
       "      <td>88</td>\n",
       "      <td>10244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>7ddu_1:A:A_model1</td>\n",
       "      <td>88</td>\n",
       "      <td>10530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>1myh_1:B:B_model1</td>\n",
       "      <td>88</td>\n",
       "      <td>10060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>1myg_1:A:A_model1</td>\n",
       "      <td>88</td>\n",
       "      <td>10156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          protein_id  class_id  number_of_points\n",
       "0             0   6vz4_3:G:G_model5        40             10134\n",
       "1             1   8g6g_3:G:G_model1        40             10180\n",
       "2             2   6vz4_3:C:C_model9        40             10190\n",
       "3             3  8tof_10:L:c_model1        40              9678\n",
       "4             4   8du4_3:G:G_model1        40             10420\n",
       "..          ...                 ...       ...               ...\n",
       "189         189   8f9j_1:A:A_model1        88             10608\n",
       "190         190   1j3f_1:A:A_model1        88             10244\n",
       "191         191   7ddu_1:A:A_model1        88             10530\n",
       "192         192   1myh_1:B:B_model1        88             10060\n",
       "193         193   1myg_1:A:A_model1        88             10156\n",
       "\n",
       "[194 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from format import Text\n",
    "import torch\n",
    "from symmetria.transformations import *\n",
    "\n",
    "#NOTE: not used\n",
    "#NOTE: also useless \n",
    "\n",
    "class BenchmarkShape():\n",
    "    def __init__(self, points):\n",
    "        self.points = points # Tensor with shape [3, N]\n",
    "    \n",
    "    def apply_rotation(self, rot):\n",
    "        ones = torch.ones((1,self.points.shape[1]))\n",
    "        self.coords = torch.concatenate((self.points, ones))\n",
    "        \n",
    "        assert rot.device == self.coords.device, \"rotation matrix and points on different devices\"\n",
    "\n",
    "        self.coords = rot@self.coords\n",
    "        \n",
    "        self.points = self.coords[:3,:]\n",
    "\n",
    "    def apply_traslation(self, x, y, z):\n",
    "        print(self.points.shape)\n",
    "        self.points[0] = self.points[0] + x\n",
    "        self.points[1] = self.points[1] + y\n",
    "        self.points[2] = self.points[2] + z\n",
    "    \n",
    "    #Applies uniform noise. n is a parameter for the amount of noise. T is the number of points to apply\n",
    "    def apply_uniform_noise(self, n, T):\n",
    "        num_points = self.points.shape[1]\n",
    "\n",
    "        indices = torch.randperm(num_points, device=self.points.device)[:T]\n",
    "    \n",
    "        self.points[:,indices] = self.points[:, indices] + (2*torch.rand(3, T, device=self.points.device)-1)/n\n",
    "    \n",
    "    def apply_gaussian_noise(self, n, T):\n",
    "        num_points = self.points.shape[1]\n",
    "\n",
    "        indices = torch.randperm(num_points, device=self.points.device)[:T]\n",
    "\n",
    "        self.points[:, indices] = self.points[:, indices] + torch.rand(3, T, device=self.points.device)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_rectangle = np.array([[0, 2, 0, 0, 2, 2, 0, 2],\n",
    "                             [0, 0, 1, 0, 1, 0, 1, 1],\n",
    "                             [0, 0, 0, 1, 0, 1, 1, 1]]).astype(np.float32)\n",
    "\n",
    "points_rectangle_t = torch.from_numpy(points_rectangle)\n",
    "\n",
    "rot = random_rotation_matrix(rotate_x=False, rotate_z=False)\n",
    "\n",
    "shapebench = BenchmarkShape(points_rectangle_t)\n",
    "#shapebench.apply_rotation(torch.from_numpy(rot))\n",
    "#shapebench.apply_traslation(1,1,0)\n",
    "#shapebench.apply_uniform_noise(100, 1)\n",
    "#shapebench.apply_gaussian_noise(100, 1)\n",
    "\n",
    "rect = pv.PolyData(shapebench.points.numpy().T)\n",
    "#rect.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "class RotateAroundZero():\n",
    "    def __init__(self, p=0.5, rot=None):\n",
    "        self.p = p\n",
    "        self.rot = rot\n",
    "\n",
    "    def __call__(self, points):\n",
    "        if random() < self.p:\n",
    "            if self.rot == None:\n",
    "                self.rot = torch.from_numpy(random_rotation_matrix())\n",
    "        \n",
    "            self.rot = self.rot.to(torch.device(points.device))\n",
    "\n",
    "            ones = torch.ones((1,points.shape[0]), device=points.device)\n",
    "            coords = torch.concatenate((torch.transpose(points, 0, 1), ones))\n",
    "            \n",
    "            coords = self.rot@coords\n",
    "            \n",
    "            points = torch.transpose(coords[:3,:], 0, 1)\n",
    "\n",
    "        return points\n",
    "    \n",
    "class Translate():\n",
    "    def __init__(self, p=0.5, shift=None, scale=1):\n",
    "        self.p = p\n",
    "        self.shift = shift\n",
    "        self.scale = scale\n",
    "\n",
    "    def __call__(self, points):        \n",
    "        if random() < self.p:\n",
    "            if self.shift == None:\n",
    "                self.shift = (torch.rand(1, device=points.device) * self.scale,\n",
    "                              torch.rand(1, device=points.device) * self.scale,\n",
    "                              torch.rand(1, device=points.device) * self.scale)\n",
    "            \n",
    "            for i in range(len(self.shift)):\n",
    "                points[:,i] += self.shift[i]\n",
    "                   \n",
    "        return points\n",
    "    \n",
    "class UniformNoise():\n",
    "    def __init__(self, n, T, p=0.5):\n",
    "        self.p = p\n",
    "        self.n, self.T = n, T\n",
    "    \n",
    "    def __call__(self, points):\n",
    "        if random() < self.p:\n",
    "            num_points = points.shape[0]\n",
    "\n",
    "            indices = torch.randperm(num_points, device=points.device)[:self.T]\n",
    "\n",
    "            points[indices,:] = points[indices,:] + (2*torch.rand(self.T, 3, device=points.device)-1)/self.n\n",
    "        \n",
    "        return points\n",
    "    \n",
    "class GaussianNoise():\n",
    "    def __init__(self, n, T, p=0.5):\n",
    "        self.p = p\n",
    "        self.n, self.T = n, T\n",
    "    \n",
    "    def __call__(self, points):\n",
    "        if random() < self.p:\n",
    "            num_points = points.shape[0]\n",
    "\n",
    "            indices = torch.randperm(num_points, device=points.device)[:self.T]\n",
    "    \n",
    "            points[indices,:] = points[indices,:] + torch.rand(self.T, 3, device=points.device)/self.n\n",
    "\n",
    "        return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_rectangle = np.array([[0, 2, 0, 0, 2, 2, 0, 2],\n",
    "                             [0, 0, 1, 0, 1, 0, 1, 1],\n",
    "                             [0, 0, 0, 1, 0, 1, 1, 1]]).astype(np.float32).T\n",
    "\n",
    "points_rectangle_t = torch.from_numpy(points_rectangle).to(torch.device('cuda:0'))\n",
    "\n",
    "translate = UniformNoise(n=10, T=8, p=0.8)\n",
    "points_rectangle_t = translate(points_rectangle_t)\n",
    "\n",
    "rect = pv.PolyData(points_rectangle)\n",
    "#rect.plot()\n",
    "\n",
    "rect_tfm = pv.PolyData(points_rectangle_t.cpu().numpy())\n",
    "#rect_tfm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef generate_train_valid_set_boring(df, val_pct, seed=42):\\n    train_size = int(len(df) * val_pct)    \\n    df_train = df.sample(train_size, random_state=seed)\\n    df_valid = df.drop(df_train.index)\\n\\n    return df_train, df_valid\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lzma\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from symmetria.transforms.RandomSampler import RandomSampler\n",
    "from symmetria.transforms.UnitSphereNormalization import UnitSphereNormalization\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, data_df, tfms, root='/mnt/dataset/shrec-2025-protein-classification/v2-20250331', extention='xz', train=True):\n",
    "        super().__init__()\n",
    "        self.df = data_df\n",
    "        self.tfms = tfms\n",
    "        self.extention = extention\n",
    "        \n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            if self.extention == 'vtk':\n",
    "                self.root = os.path.join(root, 'train')\n",
    "\n",
    "            elif self.extention == 'xz':\n",
    "                self.root = os.path.join(root, 'train-xz')\n",
    "            \n",
    "            else:\n",
    "                raise UserWarning('Extention not supported')\n",
    "            \n",
    "        else:\n",
    "            raise UserWarning('Not yet implemented for the test dataset')\n",
    "        \n",
    "        self.encode_label()\n",
    "        self.loader()\n",
    "    \n",
    "    def loader(self):\n",
    "        self.data = []\n",
    "        \n",
    "        for index in tqdm(self.df.index):\n",
    "            protein, cls, nop = self.df['protein_id'].loc[index], self.df['class_id'].loc[index], self.df['number_of_points'].loc[index]\n",
    "\n",
    "            cls_t = torch.tensor(self.encoded_cls[cls]).to(torch.device('cuda:0'))\n",
    "\n",
    "            if self.extention == 'vtk':\n",
    "                point_cloud = self.get_vtk_points(protein)\n",
    "\n",
    "            elif self.extention == 'xz':\n",
    "                point_cloud = self.get_xz_points(protein, cls, nop)\n",
    "\n",
    "            point_cloud_t = torch.from_numpy(point_cloud).to(torch.device('cuda:0'))     \n",
    "\n",
    "            point_cloud_t, cls_t = point_cloud_t.type(torch.float32), cls_t.type(torch.float32)\n",
    "            self.data.append((point_cloud_t, cls_t))\n",
    "\n",
    "    def get_vtk_points(self, name):\n",
    "        prot_file = name + '.' + self.extention\n",
    "        prot_file = os.path.join(self.root, prot_file)\n",
    "        \n",
    "        prot_mesh = pv.read(prot_file)\n",
    "\n",
    "        return prot_mesh.points\n",
    "\n",
    "    def get_xz_points(self, name, cls, nop):\n",
    "        cls, nop = str(cls), str(nop)\n",
    "\n",
    "        while len(cls) < 2:\n",
    "            cls = '0' + cls\n",
    "        \n",
    "        while len(nop) < 6:\n",
    "            nop = '0' + nop\n",
    "\n",
    "        prot_file = cls + '-' + nop +  '-' + name.replace(':', '+') + '.' + self.extention\n",
    "        prot_file = os.path.join(self.root, prot_file)        \n",
    "        \n",
    "        with lzma.open(prot_file, 'rt') as f:\n",
    "            point_cloud = np.loadtxt(f)\n",
    "\n",
    "        return point_cloud\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index, raw=False):\n",
    "        prot, cls = self.data[index]\n",
    "        \n",
    "        if not raw:\n",
    "            for tfm in self.tfms:\n",
    "                prot = tfm(prot)\n",
    "\n",
    "        return (prot, cls)\n",
    "    \n",
    "    def encode_label(self):\n",
    "        self.encoded_cls = {}\n",
    "        \n",
    "        prot_clss = self.df['class_id'].unique()\n",
    "        for idx, cls in enumerate(prot_clss):\n",
    "            self.encoded_cls[cls] = np.eye(len(prot_clss))[idx]\n",
    "\n",
    "    def render_pointcloud(self, index):\n",
    "        prot, _ = self.data[index]\n",
    "        prot = torch.transpose(prot, 0, 1).numpy()\n",
    "        cloud = pv.PolyData(prot)\n",
    "        print(cloud)\n",
    "        cloud.plot()\n",
    "    \n",
    "transforms = [Translate(p=0.8, scale=5),\n",
    "              UnitSphereNormalization(),\n",
    "              RotateAroundZero(p=0.8),\n",
    "              GaussianNoise(n=10, T=2500, p=0.8),\n",
    "              RandomSampler(sample_size=5000)]\n",
    "\n",
    "def generate_train_valid_set(df, tfms, val_pct, seed=42, **kwargs):\n",
    "    '''\n",
    "    Can also take some other arguments to be passed to the dataset initializer\n",
    "\n",
    "            -> path (str): path to the parent directory containing the train files \n",
    "    '''\n",
    "\n",
    "    train_size = int(len(df) * (1 - val_pct))    \n",
    "    df_train = df.sample(train_size, random_state=seed)\n",
    "    df_valid = df.drop(df_train.index)\n",
    "\n",
    "    return ProteinDataset(df_train, tfms, **kwargs), ProteinDataset(df_valid, tfms, **kwargs)\n",
    "\n",
    "'''\n",
    "def generate_train_valid_set_boring(df, val_pct, seed=42):\n",
    "    train_size = int(len(df) * val_pct)    \n",
    "    df_train = df.sample(train_size, random_state=seed)\n",
    "    df_valid = df.drop(df_train.index)\n",
    "\n",
    "    return df_train, df_valid\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [00:15<00:00, 67.99it/s]\n",
      "100%|██████████| 259/259 [00:03<00:00, 71.79it/s]\n"
     ]
    }
   ],
   "source": [
    "small_set = train_data_f1[train_data_f1['class_id'] == 8]\n",
    "small_set_train, small_set_valid = generate_train_valid_set(small_set, transforms, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prot type = <class 'torch.Tensor'>\n",
      "prot device = cuda:0\n",
      "prot dtype = torch.float32\n",
      "prot shape = torch.Size([19892, 3])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1929e-01, -2.5337e-01, -1.8604e-01],\n",
       "        [ 2.9123e-01, -2.5838e-01, -1.8200e-01],\n",
       "        [ 1.4469e-01, -2.5305e-01, -1.6701e-01],\n",
       "        ...,\n",
       "        [-1.4572e-01,  5.1138e-02,  7.7611e-01],\n",
       "        [-1.3106e-01,  5.1272e-04,  7.7090e-01],\n",
       "        [-1.3236e-01,  4.3181e-02,  7.7396e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = UnitSphereNormalization()\n",
    "prot, _ = small_set_train.__getitem__(0, True)\n",
    "sampler(prot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n",
      "batch\n"
     ]
    }
   ],
   "source": [
    "small_set_train_dl = DataLoader(small_set_train, batch_size=4, shuffle=True)\n",
    "\n",
    "for batch in small_set_train_dl:\n",
    "    print('batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PointNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output type = <class 'torch.Tensor'>\n",
      "output device = cpu\n",
      "output dtype = torch.float32\n",
      "output shape = torch.Size([1, 1024])\n",
      "\n",
      "output_decoder type = <class 'torch.Tensor'>\n",
      "output_decoder device = cpu\n",
      "output_decoder dtype = torch.float32\n",
      "output_decoder shape = torch.Size([1, 96])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from symmetria.encoders.pointnet_encoder import PointNetEncoder\n",
    "from symmetria.decoders.prediction_head import PredictionHead\n",
    "\n",
    "bs, sz = 1, 2048\n",
    "encoder = PointNetEncoder(use_bn=False)\n",
    "mock_x = torch.randn(bs, 3, sz)\n",
    "output = encoder.forward(mock_x)\n",
    "print(f'{Text(output, 'output'):inspect}')\n",
    "\n",
    "\n",
    "decoder = PredictionHead(1024, 96)\n",
    "output_decoder = decoder.forward(output)\n",
    "print(f'{Text(output_decoder, 'output_decoder'):inspect}')\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, output_size, use_bn=False): # make it prettier like in segmenter\n",
    "        super().__init__()\n",
    "        self.encoder = PointNetEncoder(use_bn)\n",
    "\n",
    "        self.input_size = self.get_input_size()        \n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.decoder = PredictionHead(self.input_size, self.output_size, use_bn)\n",
    "\n",
    "    def get_input_size(self):\n",
    "        mock_x = torch.randn(1, 3, 1024)\n",
    "        return self.encoder(mock_x).shape[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x #SoftMax already inside the CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [02:30<00:00,  5.31it/s]\n",
      "100%|██████████| 200/200 [00:35<00:00,  5.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import wandb\n",
    "\n",
    "test = pd.read_csv('datasets/train_set-filtered-2_cls-1000_images.csv', index_col=0)\n",
    "\n",
    "test_train_ds, test_valid_ds = generate_train_valid_set(test, 0.2, sample=10000)\n",
    "bs = 4\n",
    "test_train_dl, test_valid_dl = DataLoader(test_train_ds, batch_size=bs, shuffle=True), DataLoader(test_valid_ds, batch_size=bs, shuffle=True)\n",
    "steps_per_epoch_train = len(test_train_ds) / bs\n",
    "steps_per_epoch_valid = len(test_valid_ds) / bs\n",
    "test_net = PointNet(len(test['class_id'].unique())).to(torch.device('cuda:0'))\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(test_net.parameters(), lr=1e-3)\n",
    "EPOCHS = 10\n",
    "\n",
    "def train(train_dl, valid_dl, net, epochs):\n",
    "\n",
    "    wandb.init(project='shrec')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #print('/' * 20 + f' Epoch: {epoch + 1} ' + '/' * 20)\n",
    "        for step, batch in enumerate(tqdm(train_dl)):\n",
    "            input_p, target = batch\n",
    "\n",
    "            net.zero_grad()\n",
    "\n",
    "            output = net(input_p)\n",
    "            #print(f'{Text(output, 'output'):content}')\n",
    "            #print(f'{Text(target, 'target'):content}')\n",
    "            \n",
    "            loss = loss_func(output, target)\n",
    "            wandb.log({'epoch': epoch,\n",
    "                    'loss': loss})\n",
    "            #print(f'Training loss: {loss}')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #print('/' * 20 + ' Validation ' + '/' * 20)\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            acc = []\n",
    "            for step, batch in enumerate(tqdm(valid_dl)):\n",
    "                input_p, target = batch\n",
    "                \n",
    "                output = net(input_p)\n",
    "\n",
    "                loss = loss_func(output, target).cpu()\n",
    "                val_loss.append(loss)\n",
    "\n",
    "                matching = [torch.argmax(i) == torch.argmax(j) for i, j in zip(output, target)]\n",
    "                accuracy = matching.count(True)/len(matching)\n",
    "                acc.append(accuracy)\n",
    "            wandb.log({'epoch': epoch,\n",
    "                    'step': step,\n",
    "                    'val_loss': np.mean(val_loss),\n",
    "                    'accuracy': np.mean(acc)})\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/giorgio/venvs/SHREC/wandb/run-20250328_142437-zde4xogp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g-palmieri4998-cnr-imati/shrec/runs/zde4xogp' target=\"_blank\">stoic-glade-16</a></strong> to <a href='https://wandb.ai/g-palmieri4998-cnr-imati/shrec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g-palmieri4998-cnr-imati/shrec' target=\"_blank\">https://wandb.ai/g-palmieri4998-cnr-imati/shrec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g-palmieri4998-cnr-imati/shrec/runs/zde4xogp' target=\"_blank\">https://wandb.ai/g-palmieri4998-cnr-imati/shrec/runs/zde4xogp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 54.89it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 138.98it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.45it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 139.65it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 53.93it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 138.90it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.45it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 139.46it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.47it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 139.58it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.87it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 139.47it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.45it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 139.32it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.55it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 138.82it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 55.02it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 138.38it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.73it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 138.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▇█▄▄▃▃▁▃▁▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▂▂▃▃▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇█████</td></tr><tr><td>loss</td><td>▃▂█▃▄▄▄▃▂▃▁▁▂▂▁▁▃▂▂▂▁▃▂▁▆▂▂▂▃▄▂▂▁▁▁▁▅▂▂▁</td></tr><tr><td>step</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▁▃▃▄▄▅▄▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.09</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.09322</td></tr><tr><td>step</td><td>49</td></tr><tr><td>val_loss</td><td>5.54362</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-glade-16</strong> at: <a href='https://wandb.ai/g-palmieri4998-cnr-imati/shrec/runs/zde4xogp' target=\"_blank\">https://wandb.ai/g-palmieri4998-cnr-imati/shrec/runs/zde4xogp</a><br> View project at: <a href='https://wandb.ai/g-palmieri4998-cnr-imati/shrec' target=\"_blank\">https://wandb.ai/g-palmieri4998-cnr-imati/shrec</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250328_142437-zde4xogp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(test_train_dl, test_valid_dl, test_net, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
